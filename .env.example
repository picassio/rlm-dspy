# ============================================================================
# RLM-DSPy Environment Variables
# ============================================================================
#
# RECOMMENDED: Use 'rlm-dspy setup' to configure interactively.
# This creates ~/.rlm/config.yaml with your preferences.
#
# Copy this file to .env and customize, OR point to it with:
#   rlm-dspy setup --env-file /path/to/.env
#
# ============================================================================

# ============================================================================
# API Keys (set ONE based on your provider)
# ============================================================================

# OpenAI
OPENAI_API_KEY=sk-your-openai-key

# Anthropic
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Google (Gemini)
# GEMINI_API_KEY=your-gemini-key

# DeepSeek
# DEEPSEEK_API_KEY=sk-your-deepseek-key

# Moonshot (Kimi)
# MOONSHOT_API_KEY=sk-your-moonshot-key

# MiniMax
# MINIMAX_API_KEY=your-minimax-key

# Groq
# GROQ_API_KEY=gsk_your-groq-key

# OpenRouter (aggregator - access multiple providers)
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key

# Together AI
# TOGETHER_API_KEY=your-together-key

# Fireworks AI
# FIREWORKS_API_KEY=your-fireworks-key

# Generic override (takes precedence over provider-specific keys)
# RLM_API_KEY=your-api-key

# ============================================================================
# Model Selection
# ============================================================================

# Model format: provider/model-name
# Examples:
#   openai/gpt-4o              - GPT-4 Omni
#   openai/gpt-4o-mini         - Fast, cheap GPT-4
#   anthropic/claude-sonnet-4-20250514  - Claude Sonnet 4
#   deepseek/deepseek-chat     - DeepSeek V3
#   deepseek/deepseek-r1       - DeepSeek reasoning
#   moonshot/kimi-latest       - Kimi
#   minimax/MiniMax-M2.1       - MiniMax (reasoning)
#   gemini/gemini-2.0-flash    - Gemini Flash
#   groq/llama-3.1-70b-versatile  - Llama via Groq
#   ollama/llama3.2            - Local Ollama
#   openrouter/google/gemini-2.0-flash-001  - Via OpenRouter

RLM_MODEL=openai/gpt-4o-mini

# Sub-model for llm_query() calls in REPL (optional, defaults to RLM_MODEL)
# Use a cheaper/faster model for sub-queries to reduce costs
# RLM_SUB_MODEL=openai/gpt-4o-mini

# Custom API endpoint (only needed for self-hosted or proxies)
# RLM_API_BASE=http://localhost:8000/v1

# ============================================================================
# RLM Execution Settings
# ============================================================================
# RLM uses a REPL-based approach where the LLM writes Python code to explore
# your context. These settings control the execution limits.

# Maximum REPL iterations (default: 20)
# Each iteration = LLM writes code, sees output, decides next step
RLM_MAX_ITERATIONS=20

# Maximum sub-LLM calls per execution (default: 50)
# The LLM can call llm_query() to analyze specific sections
RLM_MAX_LLM_CALLS=50

# Maximum characters to include from REPL output (default: 100000)
# Prevents context overflow from large print statements
RLM_MAX_OUTPUT_CHARS=100000

# Enable verbose logging (default: false)
# Shows each iteration's reasoning and code
# RLM_VERBOSE=true

# ============================================================================
# Safety Limits
# ============================================================================

# Maximum cost in USD per query (default: 1.0)
RLM_MAX_BUDGET=1.0

# Maximum execution time in seconds (default: 300)
RLM_MAX_TIMEOUT=300

# ============================================================================
# Example Configurations
# ============================================================================

# --- Cheapest (DeepSeek) ---
# DEEPSEEK_API_KEY=sk-...
# RLM_MODEL=deepseek/deepseek-chat
# RLM_SUB_MODEL=deepseek/deepseek-chat
# RLM_MAX_BUDGET=0.10

# --- Fastest (Groq) ---
# GROQ_API_KEY=gsk_...
# RLM_MODEL=groq/llama-3.1-70b-versatile
# RLM_MAX_ITERATIONS=10

# --- Best Quality (Claude) ---
# ANTHROPIC_API_KEY=sk-ant-...
# RLM_MODEL=anthropic/claude-sonnet-4-20250514
# RLM_MAX_BUDGET=5.0
# RLM_MAX_ITERATIONS=30

# --- Cost-Optimized (GPT-4o + Mini for sub-queries) ---
# OPENAI_API_KEY=sk-...
# RLM_MODEL=openai/gpt-4o
# RLM_SUB_MODEL=openai/gpt-4o-mini
# RLM_MAX_BUDGET=2.0

# --- Local (Ollama) ---
# RLM_MODEL=ollama/llama3.2
# RLM_MAX_BUDGET=0  # Free!
# RLM_MAX_ITERATIONS=30  # Can be more generous with local

# --- Chinese Providers ---
# DEEPSEEK_API_KEY=sk-...
# RLM_MODEL=deepseek/deepseek-chat
#
# MOONSHOT_API_KEY=sk-...
# RLM_MODEL=moonshot/kimi-latest
#
# MINIMAX_API_KEY=...
# RLM_MODEL=minimax/MiniMax-M2.1
