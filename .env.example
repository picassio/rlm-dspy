# ============================================================================
# RLM-DSPy Environment Variables
# ============================================================================
#
# RECOMMENDED: Use 'rlm-dspy setup' to configure interactively.
# This creates ~/.rlm/config.yaml with your preferences.
#
# Copy this file to .env and customize, OR point to it with:
#   rlm-dspy setup --env-file /path/to/.env
#
# ============================================================================

# ============================================================================
# API Keys (set ONE based on your provider)
# ============================================================================

# OpenAI
OPENAI_API_KEY=sk-your-openai-key

# Anthropic
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Google (Gemini)
# GEMINI_API_KEY=your-gemini-key

# DeepSeek
# DEEPSEEK_API_KEY=sk-your-deepseek-key

# Moonshot (Kimi)
# MOONSHOT_API_KEY=sk-your-moonshot-key

# MiniMax
# MINIMAX_API_KEY=your-minimax-key

# Groq
# GROQ_API_KEY=gsk_your-groq-key

# OpenRouter (aggregator - access multiple providers)
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key

# Together AI
# TOGETHER_API_KEY=your-together-key

# Fireworks AI
# FIREWORKS_API_KEY=your-fireworks-key

# Generic override (takes precedence over provider-specific keys)
# RLM_API_KEY=your-api-key

# ============================================================================
# Model Selection
# ============================================================================

# Model format: provider/model-name
# Examples:
#   openai/gpt-4o              - GPT-4 Omni
#   openai/gpt-4o-mini         - Fast, cheap GPT-4
#   anthropic/claude-sonnet-4-20250514  - Claude Sonnet 4
#   deepseek/deepseek-chat     - DeepSeek V3
#   deepseek/deepseek-r1       - DeepSeek reasoning
#   moonshot/kimi-latest       - Kimi
#   minimax/MiniMax-M2.1       - MiniMax (reasoning)
#   gemini/gemini-2.0-flash    - Gemini Flash
#   groq/llama-3.1-70b-versatile  - Llama via Groq
#   ollama/llama3.2            - Local Ollama
#   openrouter/google/gemini-2.0-flash-001  - Via OpenRouter

RLM_MODEL=openai/gpt-4o-mini

# Sub-model for lightweight tasks (optional, defaults to RLM_MODEL)
# RLM_SUB_MODEL=openai/gpt-4o-mini

# Custom API endpoint (only needed for self-hosted or proxies)
# RLM_API_BASE=http://localhost:8000/v1

# ============================================================================
# Execution Limits
# ============================================================================

# Maximum cost in USD per query (default: 1.0)
RLM_MAX_BUDGET=1.0

# Maximum execution time in seconds (default: 300)
RLM_MAX_TIMEOUT=300

# Maximum tokens to process (default: 500000)
# RLM_MAX_TOKENS=500000

# ============================================================================
# Chunking Configuration
# ============================================================================

# Chunk size in characters (default: 100000)
RLM_CHUNK_SIZE=100000

# Enable syntax-aware chunking with tree-sitter (default: true)
# Chunks at function/class boundaries instead of arbitrary positions
RLM_SYNTAX_AWARE=true

# ============================================================================
# Processing Configuration
# ============================================================================

# Maximum concurrent chunks (default: 20)
RLM_PARALLEL_CHUNKS=20

# Use async HTTP for parallel requests (default: true)
RLM_USE_ASYNC=true

# ============================================================================
# Example Configurations
# ============================================================================

# --- Cheapest (DeepSeek) ---
# DEEPSEEK_API_KEY=sk-...
# RLM_MODEL=deepseek/deepseek-chat
# RLM_MAX_BUDGET=0.10

# --- Fastest (Groq) ---
# GROQ_API_KEY=gsk_...
# RLM_MODEL=groq/llama-3.1-70b-versatile
# RLM_PARALLEL_CHUNKS=50

# --- Best Quality (Claude) ---
# ANTHROPIC_API_KEY=sk-ant-...
# RLM_MODEL=anthropic/claude-sonnet-4-20250514
# RLM_MAX_BUDGET=5.0

# --- Local (Ollama) ---
# RLM_MODEL=ollama/llama3.2
# RLM_MAX_BUDGET=0  # Free!

# --- Chinese Providers ---
# DEEPSEEK_API_KEY=sk-...
# RLM_MODEL=deepseek/deepseek-chat
#
# MOONSHOT_API_KEY=sk-...
# RLM_MODEL=moonshot/kimi-latest
#
# MINIMAX_API_KEY=...
# RLM_MODEL=minimax/MiniMax-M2.1
